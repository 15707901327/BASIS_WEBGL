<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>主页</title>
  <link rel="stylesheet" href="css/base.css">
</head>
<body>
<div class="l-r-wrapper">
  <div class="left">
    <h4><a href="#basicConcept">基本概念</a></h4>
    <ul class="ul-1">
      <li><a href="#pipeline">渲染管线</a></li>
      <li><a href="#WebGL">WebGL程序</a></li>
      <li><a href="#WebGL_System">着色器</a></li>
      <li><a href="#camera">相机</a></li>
      <li><a href="WebGL_API/WebGL可以绘制的基本图形.html" target="_blank">WebGL绘制的基本图形</a></li>
      <li><a href="WebGL_API/canvas标签.html" target="_blank">canvas标签</a></li>
      <li><a href="#type_array">类型化数组</a></li>
      <li><a href="#noise">图形噪声</a></li>
    </ul>
    <h4><a href="#texture">texture</a></h4>
    <h4><a href="#blending">blending</a></h4>
    <ul class="ul-1">
      <li><a href="#blendFunc">混合功能</a></li>
    </ul>
    <h4><a href="#toneMapping">Tone Mapping</a></h4>
    <ul class="ul-1">
      <li><a href="#hdr">HDR</a></li>
    </ul>
    <h4><a href="#bloom">bloom</a></h4>
    <h4><a href="#buffer">缓冲区</a></h4>
    <ul class="ul-1">
      <li><a href="#bufferObject">缓冲区对象</a></li>
      <li><a href="#depthBuffer">深度缓冲区</a></li>
      <li><a href="#renderbufferObject">渲染缓冲区对象</a></li>
      <li><a href="#framebuffer">帧缓冲区对象</a></li>
    </ul>
    <h4><a href="#WebGL_Event">WebGL相关事件</a></h4>
    <ul class="ul-1">
      <li><a href="#ContextLost">上下文丢失事件</a></li>
    </ul>
    <h4><a href="#inner">WebGL内置功能</a></h4>
    <ul class="ul-1">
      <li><a href="#depth_test">隐藏面消除</a></li>
      <li><a href="#ploygonOffset">多边形偏移</a></li>
      <li><a href="#blendFunc">混合功能</a></li>
      <li><a href="#polygonCulling">多边形剔除</a></li>
    </ul>
    <h4><a href="#light">光照</a></h4>
    <h4><a href="WebGL_API/GraphicsDOC/index.html" target="_blank">图形学（Graphics）</a></h4>
    <h4><a href="canvas%202D%20API/ctx.html" target="_blank">canvas 2D API</a></h4>
    <h4><a href="WebGL_API/js_API/gl.html" target="_blank">WebGL API</a></h4>
    <h4><a href="WebGL_API/js_API/WebGL_extensions.html" target="_blank">WebGL扩展注册表</a></h4>
    <h4><a href="#WebGL-example">WebGL实例</a></h4>
    <ul class="ul-1">
      <li><a href="#example_1">WebGL编程指南</a></li>
      <li><a href="#example_2">WebGL水箱效果</a></li>
      <li><a href="PGL/index.html" target="_blank">PGL实例</a></li>
      <li><a href="交互式计算机图形学第七版/index.html" target="_blank">交互式计算机图形学第七版</a></li>
    </ul>
    <h4><a href="#book">相关资料</a></h4>
  </div>
  <div class="right">
    <section id="basicConcept" class="section1">
      <h4 class="title">WebGL中的基本概念</h4>
      <section>
        <h4>基本概念</h4>
        <div class="content">
          <strong>绘图</strong>
          <p>WebGl在颜色缓冲区中进行绘图，在开启隐藏面消除功能时，还会用到深度缓冲区。总之，绘图的结果图像是存储在颜色缓冲区中的。</p>
          <strong>图元光栅化:</strong>
          <p>发生在顶点着色器和片元着色器之间的从图形到片元的转化过程。</p>
          <strong>顶点（vertex)</strong>
          <p>指二维或三维空间中的一个点，比如二维或三维图形的端点或交点。</p>
          <strong>片元（Fragment）：</strong>
          <p>片元就是显示在屏幕上的一个像素（严格意义上来说，片元包括这个像素的位置、颜色和其他信息）。</p>
          <strong>图形装配过程：</strong>
          <p>将孤立的顶点坐标装配成几何图形。</p>
          <strong>光栅化过程：</strong>
          <p>将装配好的几何图形转化为片元。一旦光栅化过程结束后，程序就开始逐片元调用片元着色器。</p>
          <strong>深度检测（DEPTH_TEST）：</strong>
          <p>通过检测物体（的每个像素的）的深度来决定是否将其画出来。</p>
          <strong>深度冲突：</strong>
          <p>产生深度冲突的原因是：在使用隐藏面消除时，当几何图形或物体的两个表面极为接近时，<a href="#depthBuffer">深度缓冲区</a>有限的精度已经不能区分出那个在前，那个在后,就会发生深度冲突的问题.
          </p>
          <p>WebGL提供一种<a href="#ploygonOffset">多边形偏移的机制来解决这个问题。</a></p>
        </div>
      </section>
      <section id="pipeline">
        <h4>渲染管线</h4>
        <div class="content">
          <div><img src="img/pipeline.png"/></div>
          <p>渲染管线指的是WebGL程序的执行过程，如上图所示，主要分为 4 个步骤：</p>
          <ul class="ul-1-num">
            <li>顶点着色器的处理，主要是一组矩阵变换操作，用来把3D模型（顶点和原型）投影到viewport上，输出是一个个的多边形，比如三角形。</li>
            <li>光栅化，也就是把三角形连接区域按一定的粒度逐行转化成片元（fragement），类似于2D空间中，可以把这些片元看做是3D空间的一个像素点。</li>
            <li>片元着色器的处理，为每个片元添加颜色或者纹理。只要给出纹理或者颜色，以及纹理坐标(uv)，管线就会根据纹理坐标进行插值运算，将纹理或者图片着色在相应的片元上。</li>
            <li>把3D空间的片元合并输出为2D像素数组并显示在屏幕上。</li>
          </ul>
        </div>
      </section>
      <section id="WebGL">
        <h4>WebGL程序</h4>
        <p>WebGL程序包括运行在浏览器中的JavaScript和运行在WebGL系统中的<a href="#WebGL_System">着色器程序</a>这两个部分。 </p>
        <div class="content">
          <strong>将信息从JavaScript程序中传递给顶点着色器，由两种方式可以做到：</strong>
          <ul class="ul-1">
            <li><a href="WebGL_API/shader API/存储限定字.html#attribute" target="_blank">attribute变量</a></li>
            <li><a href="WebGL_API/shader API/存储限定字.html#uniform" target="_blank">uniform变量</a></li>
          </ul>
        </div>
      </section>
      <section id="WebGL_System">
        <h4>着色器</h4>
        <p>WebGL需要两种着色器，即顶点着色器（Vertex shader）和片元着色器（Fragment shader）。着色器运行在WebGL系统中。</p>
        <div class="content">
          <strong>顶点着色器（Vertex shader）</strong>
          <p>顶点着色器用用来描述顶点特性（如位置、颜色等）的程序。</p>
          <strong>片元着色器（Fragment shader）。</strong>
          <p>使其显示在屏幕上。进行逐片元处理过程如光照的程序。</p>
          <strong>WebGL中的着色器详细说明：</strong>
          <p><a href="WebGL_API/shader_API/index.html" target="_blank">shader（GLSL ES）</a></p>
        </div>
      </section>
      <section id="camera">
        <h4>相机</h4>
        <div class="content">
          <h4>三维投影算法</h4>

          <p>三维空间中的物体，投射在相机视平面的转换算法。</p>
          <p><strong>相机看到的景象和以下因素有关：</strong></p>
          <ul class="ul-3-num">
            <li>相机的投影类型（正射投影、透视投影）：投影矩阵（ProjectMatrix）</li>
            <li>相机的位置和方向：视图矩阵 ( CameraMatrixWorldInverse 或 ViewMatrix )</li>
            <li>物体的位置和形变（旋转/缩放/平移）：物体位置矩阵( ObjectWorldMatrix )</li>
          </ul>
          <p>三维投影算法就是将上诉因素抽象为数学算法，用来计算三维物体在相机视平面上的位置。实际应用中我们是通过矩阵计算来实现的。简而言之，我们将相机的位置方向, 相机的类型, 物体的位置和形变能转换为
            矩阵 , 将这些矩阵进行一系列计算后, 最终得到 三维投影矩阵.</p>

          <p><strong>三维投影矩阵计算公式：</strong></p>
          <p>uMatrix = ProjectMatrix * CameraMatrixWorldInverse * ObjectMatrixWorld</p>

          <p><strong>相机的视图矩阵:</strong></p>
          <p>视图矩阵的含义是，固定其他因素，我们改变了相机的位置和角度后，它眼中的世界也会发生变化，这种变化就是视图矩阵。</p>
          <p>相机在三维空间中的位置是 camera.matrixWorld ，而它的视图矩阵是相机位置矩阵的逆矩阵 CameraMatrixWorldInverse ，它也符合了我们的生活经验：</p>
          <ul class="ul-3-num">
            <li>固定相机，人向左移动</li>
            <li>固定人，向右移动相机</li>
          </ul>

          <h4>相机的可视空间：</h4>
          <ul class="ul-1-num">
            <li>长方形可视空间，也称盒状空间，由正射投影（orthographic projection）产生。</li>
            <li>四棱锥/金字塔可视空间，由透视投影(perspective projection)产生</li>
          </ul>

          <h4>获取屏幕二维坐标:</h4>
          <p>const [x, y] = ProjectionMatrix * CameraWorldMatrixInverse * [x, y, z]</p>

          <h4>屏幕坐标转化为三维坐标:</h4>
          <p>const [x, y, z] = CameraWorldMatrix * ProjectionMatrixInverse * [x, y, z]</p>
          <p>不过屏幕坐标转化为三维坐标不是这么简单，因为屏幕上的二维坐标在三维空间中其实对应的是一条射线，其可以对应了无限个三维坐标点.</p>
        </div>
      </section>
      <section id="type_array">
        <h4>类型化数组</h4>
        <p>WebGL通常需要同时处理大量相同类型的数据，为了优化性能，WebGL为每种基本数据类型引入了一种特殊的数组（类型化数组）。</p>
        <div class="content">
          <strong>WebGL使用的各种类型化数组：</strong>
          <table border="1">
            <tr>
              <th colspan="3">
                WebGL使用的各种类型化数组
              </th>
            </tr>
            <tr>
              <th>类型数组</th>
              <th>每个元素所占据的字节数</th>
              <th>描述（C语言中的数据类型）</th>
            </tr>
            <tr>
              <td>Int8Array</td>
              <td>1</td>
              <td>8位整型数（signed char）</td>
            </tr>
            <tr>
              <td>UInt8Array</td>
              <td>1</td>
              <td>8位无符号整型数（unsigned char）</td>
            </tr>
            <tr>
              <td>Int16Array</td>
              <td>2</td>
              <td>16位整型数（signed short）</td>
            </tr>
            <tr>
              <td>UInt16Array</td>
              <td>2</td>
              <td>16位无符号整型数（unsigned short）</td>
            </tr>
            <tr>
              <td>Int32Array</td>
              <td>4</td>
              <td>32位整型数（signed int）</td>
            </tr>
            <tr>
              <td>UInt32Array</td>
              <td>4</td>
              <td>32位无符号整型数（unsigned int）</td>
            </tr>
            <tr>
              <td>Float32Array</td>
              <td>4</td>
              <td>单精度32位浮点数（float）</td>
            </tr>
            <tr>
              <td>Float64Array</td>
              <td>8</td>
              <td>双精度64位浮点数（double）</td>
            </tr>
          </table>
          <strong>类型化数组的方法、属性和常量：</strong>
          <table border="1">
            <tr>
              <th colspan="3">类型化数组的方法、属性和常量</th>
            </tr>
            <tr>
              <th>方法、属性和常量</th>
              <th>描述</th>
              <th>实例</th>
            </tr>
            <tr>
              <td>get(index)</td>
              <td>获取第index个元素值</td>
              <td></td>
            </tr>
            <tr>
              <td>set(index,value)</td>
              <td>设置第index个元素的值value</td>
              <td></td>
            </tr>
            <tr>
              <td>set(array,offset)</td>
              <td>从第offset个元素开始将数组array中的值填充进去</td>
              <td></td>
            </tr>
            <tr>
              <td>length</td>
              <td>数组的长度</td>
              <td></td>
            </tr>
            <tr>
              <td>BYTES_PER_ELEMENT</td>
              <td>数组中每个元素所占据的字节数</td>
              <td>
                <ul>
                  <li><a href="../WebGL编程指南/ch5/MultiAttributeSize_interleaved.html">使用一个类型化数组来存储顶点的位置和顶点的大小</a>
                  </li>
                </ul>
              </td>
            </tr>
          </table>
          <strong>类型化数组的创建</strong>
          <p>类型化数组可以通过new运算符调用构造函数并传入数据而被创造出来。也可以指定数组元素的个数来创建一个空的类型化的数组。</p>
          <strong>注意：</strong>
          <ul class="ul-1">
            <li>
              类型化数组不能使用[]运算符（这样创建的是一个普通的数组）
            </li>
          </ul>
        </div>
      </section>
      <section id="noise">
        <h4>图形噪声</h4>
        <p>图形噪声，是计算机图形学中一类随机算法，经常用来模拟自然界中的各种纹理材质，如云、山脉等，都是通过噪声算法模拟出来的​。</p>
        <p><a href="WebGL_API/Noise.html" target="_blank">详细说明</a></p>
      </section>
    </section>
    <section id="texture" class="section1">
      <h4 class="title">texture</h4>
      <section>
        <h4>基本概念</h4>
        <p>纹理是数据的简单矩阵排列——比如。颜色数据、亮度数据或者颜色和alpha（透明度）数据。</p>
        <div class="content">
          <strong>纹理单元：</strong>
          <p>纹理数组中的每个独立的数值通常称为一个纹理单元.</p>
          <strong>纹理映射：</strong>
          <p>一种将<strong>纹理图像</strong>应用于物体表面的技术（就是把图像贴到构成物体表面的多边形上去），就像该图像是
            一种贴画纸或玻璃纸附着于物体的表面上。此时，这张图像又可以称为<strong>纹理图像（texture image）</strong>或
            <strong>纹理（texture）</strong>。</p>
          <strong>纹理坐标：</strong>
          <p></p>
          <strong>MipMap：</strong>
          <p>Mipmap由Lance Williams 在1983的一篇文章“Pyramidal
            parametrics”中提出。Wiki中有非常具体的介绍(http://en.wikipedia.org/wiki/Mipmap
            )。比方一张256X256的图，在长和宽方向每次降低一倍，生成：128X128, 64X64, 32X32, 16X16, 8X8, 4X4, 2X2, 1X1 八张图，组成MipMap。</p>
          <p>
            Mipmap早已被硬件支持，硬件会自己主动为创建的Texture生成mipmap的各级。在D3D的API：CreateTexture中有一个參数levels，就是用于指定生成mipmap到哪个级别，当不指定时就一直生成到1X1。</p>
          <strong>各向同性:</strong>
          <p>当须要贴图的三维表面平行于屏幕(viewport)，则是各向同性的。</p>
          <strong>各向异性：</strong>
          <p>当要贴图的三维表面与屏幕有一定角度的倾斜，则是各向异性的。</p>
        </div>
      </section>
      <section>
        <h4>纹理过滤</h4>
        <p>当三维空间里面的多边形经过坐标变换、投影、光栅化等过程，变成二维屏幕上的一组象素的时候。对每一个象素须要到对应纹理图像中进行採样，这个过程就称为纹理过滤。</p>
        <div class="content">
          <strong>过滤模式：</strong>
          <ul class="ul-3-num">
            <li>Nearest Point Sampling（近期点採样):仅仅是针对每个象素对最接近它的纹理单元进行採样。可用于上面两种情况。
              可是这样的纹理过滤方法的效果最差，在屏幕显示的图像会显得十分模糊。
            </li>
            <li>Bilinear（双线性过滤）:每个象素要对最接近它的2 x 2的纹理单元矩阵进行採样，取4个纹理单元的平均值。也可用于上面的两种情况。这样的纹理过滤方法的效果比上面的要好非常多。<br>
              双线性过滤像素之间的过渡更加平滑，可是它仅仅作用于一个MipMap Level,它选取texel和pixel之间大小最接近的那一层MipMap进行採样。当和pixel大小匹配的texel大小在两层Mipmap
              level之间时，双线性过滤在有些情况效果就不太好。于是就有了三线性过滤。
            </li>
            <li>
              Trilinear（三线性过滤）:三线性过滤相对的比較复杂，它仅仅能用于纹理被缩小的情况，须要先构造纹理图像的mipmap，mip的意思是“在狭窄的地方里的很多东西”，mipmap就是对最初的纹理图像构造的一系列分辨率降低而且预先过滤的纹理图。对于一个8
              x 8的纹理来说须要为它构造4 x 4、2 x 2、1 x 1这三个mipmap。
              <p>假设正方形被缩小到在屏幕上占6 x 6的象素矩阵，一个象素的採样过程就变成这样。首先是到8 x 8的纹理图中进行对最接近它2 x 2的纹理单元矩阵进行採样（也就是上面的线性过滤）；其次是到4 x
                4的纹理图中反复上面的过程；接着把上面两次採样的结果进行加权平均，得到最后的採样数据。能够看出整个过程一共进行了三次的线性过滤。所以这样的方法叫做三线性过滤，它的效果是三种纹理过滤方法里面最好的。</p>
            </li>
            <li>Anisotropic Filtering（各向异性过滤）:
              <p>各向异性过滤让表面倾斜物体纹理更加清晰锐利同一时候看上去非常密集。透明度又让密集的纹理变得模糊平缓。各异向性纹理过滤不是单独使用而是和前面所述的其它过滤方法结合一起使用的。</p>
              <p>
                如果Px为纹理在x坐标方向上的缩放的比例因子。Py为纹理在y坐标方向上的缩放的比例因子。Pmax为Px和Py中的最大值。Pmin为Px和Py中的最小值。当Pmax/Pmin等于1时。也就是说Px等于Py，纹理的缩放是各同向的；可是如果Pmax/Pmin不等于1而是大于1，Px不等于Py，也就是说纹理在x坐标方向和在y坐标方向缩放的比例不一样，纹理的缩放是各异向的，Pmax/Pmin代表了各异向的程度。</p>
              <p> 举个样例来说，64 x 64的纹理贴到一个開始平行于xy平面的正方形上。可是正方形绕y轴旋转60度。最后投影到屏幕上占了16 x 32的象素矩阵。
                纹理在x坐标方向上缩放的比例因子为64/16等于4，在y坐标方向缩放的比例因子为64/32等于2，Pmax等于4，Pmin等于2。缩放的各异向程度为2。
                当把各异向性过滤和线性过滤结合起来的时候。应该是对最接近象素的4 x 2的纹理单元矩阵採样才合理，由于一个象素在x坐标方向上相应了很多其它的纹理单元（Px > Py）。</p>
              <p>
                即使是纹理在一个轴方向上缩小而在还有一个轴方向上放大，处理的过程也是一样的（注意的是如果纹理在一个轴方向上缩小而在还有一个轴方向上放大，OpenGL仍然把它当作是纹理被缩小的情况。将採用为纹理缩小情况设置的过滤方法为基本过滤方法。然后再加上各异向性过滤）。如果被贴图的正方形最后在屏幕上占了一个128
                x 32 的象素矩阵。纹理在x坐标方向上缩放的比例因子为64/128等于0.5，在y坐标方向缩放的比例因子为64/32等于2，因为Py > Px 且
                Pmax/Pmin等于4，所以当把各异向性过滤和线性过滤结合起来的时候。应该对最接近象素的2 x 8的纹理单元矩阵进行採样。</p>
            </li>
          </ul>
          <strong>纹理过滤通常分为2种情况：</strong>
          <p>纹理被缩小:比方说一个8 x 8的纹理贴到一个平行于xy平面的正方形上，最后该正方形在屏幕上仅仅占4 x 4的象素矩阵，这样的情况下一个象素相应着多个纹理单元。</p>
          <p>纹理被放大:这样的情况刚好跟上面相反。假如我们放大该正方形，最后正方形在屏幕上占了一个16 x 16的象素矩阵，这样就变成一个纹理单元相应着多个象素。</p>
        </div>
      </section>
    </section>
    <section id="blending" class="section1">
      <div class="title">blending</div>
      <p>blending是一种颜色和另一种颜色相结合，以获取第三种颜色的行为。我们看到现实世界中一直存在混合：光线穿过玻璃、光线从表面反射、光源叠加到背景上、耀斑、夜晚周围点亮的灯。</p>
      <p>OpenGL提供了多种不同的混合模式来模拟这些效果。在OpenGL中,混合发生在渲染过程的后期阶段:一旦片源着色器计算出片源的最终输出颜色，并把颜色写入到<a href="#framebuffer">帧缓冲区</a>中，就会发生混合。
        通常情况下，片源仅仅覆盖之前的所有内容，但是如果打开混合，片源将与之前的片源混合。</p>
      <p>OpenGL通过混合方程来控制混合效果，因此我们可以通过控制混合方程以及混合方程参数来控制混合效果。</p>
      <p>使用<a href="WebGL_API/js_API/gl.html#blendEquation" target="_blank">gl.BlendEquation()</a>、<a
          href="WebGL_API/js_API/gl.html#blendEquationSeparate" target="_blank">gl.blendEquationSeparate()</a>方法来设置混合方程。
        默认情况下，OpenGL中混合方程默认设置为GL_FUNC_ADD(<a href="WebGL_API/js_API/gl.html#blending_equation"
                                             target="_blank">混合方程详细说明</a>)。</p>
      <p>使用<a href="WebGL_API/js_API/gl.html#blendFunc" target="_blank">gl.blendFunc(src_factor, dst_factor)</a>方法来设置混合方程参数
        (<a href="WebGL_API/js_API/gl.html#blending_equation_param" target="_blank">混合方程参数说明</a>)。
      </p>
      <p>常用的混合方程参数设置：Additive blending、Multiplicative blending、Interpolative blending</p>
      <section>
        <h4>Additive blending</h4>
        <p>将不同颜色添加到一起并添加结果时所做的混合类型。这就是我们的视觉与光一起工作的方式，这就是我们如何在我们的显示器上感知数百万种不同的颜色 - 它们实际上只是将三种不同的原色混合在一起。</p>
        <p>这种类型的混合在3D渲染中具有许多用途，例如在粒子效果中，其似乎发出光或覆盖物，例如围绕光的电晕，或围绕光剑的发光效果。</p>
        <p>可以通过调用<a href="WebGL_API/js_API/gl.html#blendFunc"> gl.BlendFunc(GL_ONE，GL_ONE) </a>来指定加法混合。 这导致混合方程output =
          (1 * source fragment) + (1 * destination fragment)，其折叠成output = source fragment + destination fragment.</p>
      </section>
      <section>
        <h4>Multiplicative blending</h4>
        <p>表示光在通过滤色器时的行为方式，或者从被点亮的物体反射并进入我们的眼睛时的行为。红色物体对我们来说是红色的，因为当白光照射到物体上时，蓝色和绿色光被吸收。 只有红光反射回我们的眼睛。
          在左边的例子中，我们可以看到一个表面反射一些红色和一些绿色，但很少蓝色。</p>
        <p>当多纹理不可用时，乘法混合用于在游戏中实现光照贴图。 纹理与光照贴图相乘，以填充亮起和阴影区域。</p>
        <p>可以通过调用<a href="WebGL_API/js_API/gl.html#blendFunc">gl.BlendFunc(GL_DST_COLOR，GL_ZERO)</a>来指定乘法混合。
          这导致混合方程output = (destination fragment * source fragment) + (0 * destination fragment)，其折叠成output = source
          fragment * destination fragment.</p>
      </section>
      <section>
        <h4>Interpolative blending</h4>
        <p>结合了Additive blending和Multiplicative blending，以提供插值效果。
          与自身的加法和调制不同，这种混合模式也可以依赖于绘制顺序，因此在某些情况下，如果先绘制最远的半透明对象，然后再绘制较近的半透明对象，结果才会正确。
          即使排序也不是完美的，因为三角形可能重叠并相交，但产生的伪像可能是可接受的。</p>
        <p>插值通常用于将相邻表面混合在一起，以及做有色玻璃或淡入/淡出等效果。 左侧的图像显示了使用插值混合在一起的两个纹理。</p>
        <p>通过调用<a href="WebGL_API/js_API/gl.html#blendFunc">gl.BlendFunc（GL_SRC_ALPHA，GL_ONE_MINUS_SRC_ALPHA）</a>指定插值。
          这导致混合方程output = (source alpha * source fragment) + ((1 – source alpha) * destination fragment).</p>
      </section>
      <section>
        <h4>资料地址</h4>
        <p>http://www.learnopengles.com/android-lesson-five-an-introduction-to-blending/</p>
      </section>
      <section id="blendFunc">
        <h4>混合功能</h4>
        <p>实现半透明效果。</p>
        <div class="content">
          <strong>启动功能</strong>
          <ul class="ul-1-num">
            <li>
              开启混合功能<br>
              <a href="WebGL%20API/javaScript%20API/gl.html#enable">gl.enable(gl.BLEND)</a>
            </li>
            <li>
              指定混合函数<br>
              <a href="WebGL%20API/javaScript%20API/gl.html#blendFunc">gl.blendFunc(gl.SRC_ALPHA,
                gl.ONE_MINUS_SRC_ALPHA)</a>
            </li>
          </ul>
          <strong>实例</strong>
          <ul class="ul-1-num">
            <li><a href="WebGL编程指南/ch10/LookAtBlendedTriangles.html" target="_blank">α混合</a></li>
          </ul>
          <strong>透明与不透明物体共存:</strong>
          <ul class="ul-1-num">
            <li>
              开启隐藏面消除功能<br>
              <a href="WebGL%20API/javaScript%20API/gl.html#enable">gl.enable(DEPTH_TEST)</a>
            </li>
            <li>
              绘制所有不透明的物体<br>
            </li>
            <li>
              锁定用于进行隐藏面消除的深度缓存区的写入操着，使之只读。<br>
              <a href="WebGL%20API/javaScript%20API/gl.html#depthMask">gl.depthMask(false)</a>
            </li>
            <li>绘制所有半透明的物体（α小于1.0），注意他们应当按照深度排序，然后从后向前绘制</li>
            <li>
              释放深度缓存区，使之可读可写。<br>
              <a href="WebGL%20API/javaScript%20API/gl.html#depthMask">gl.depthMask(false)</a>
            </li>
          </ul>
        </div>
      </section>
    </section>
    <section id="toneMapping" class="section1">
      <div class="title">Tone Mapping</div>
      <p>色调映射(Tone Mapping)是一个损失很小的转换浮点颜色值至我们所需的<a href="#ldr">LDR</a>[0.0, 1.0]范围内的过程，
        通常会伴有特定的风格的色平衡(Stylistic Color Balance)。</p>
      <section>
        <h4>Reinhard色调映射算法</h4>
        <img src="img/ReinhardToneMapping.jpg" align="right">
        <p>Reinhard色调映射是最简单的色调映射算法，它涉及到分散整个<a href="#hdr">HDR</a>颜色值到<a href="#ldr">LDR</a>
          颜色值上，所有的值都有对应。Reinhard色调映射算法平均地将所有亮度值分散到<a href="#ldr">LDR</a>上。</p>
        <p>使用Reinhard tone mapping operator后，图片细节得以保留，而线性映射会造成最亮的区域和最暗的区域信息丢失。
          但缺点也很明显，就是灰暗。个个颜色都朝着灰色的方向被压缩了，画面像蒙了一层纱。 图中书本效果：</p>
        <p><strong>Reinhard tone mapping:</strong></p>
        <pre>
          float3 ReinhardToneMapping(float3 color, float adapted_lum){
              const float MIDDLE_GREY = 1;
              color *= MIDDLE_GREY / adapted_lum;
              return color / (1.0f + color);
          }
        </pre>
        <ul class="ul-3">
          <li>color:线性的HDR颜色</li>
          <li>adapted_lum:根据整个画面统计出来的亮度。</li>
          <li>MIDDLE_GREY：表示把什么值定义成灰。这个值就是纯粹的magic number了，根据需要调整。</li>
        </ul>
        <p>Reinhard的曲线是这样的，可以看出总体形状是个S型:</p>
        <p><img src="img/ReinhardToneMapping2.png"></p>
        <p>
          将Reinhard
          色调映射应用到之前的片段着色器上，并且加上一个Gamma校正过滤：</p>
        <pre>
          void main(){
            const float gamma = 2.2;
            vec3 hdrColor = texture(hdrBuffer, TexCoords).rgb;
            // Reinhard色调映射
            vec3 mapped = hdrColor / (hdrColor + vec3(1.0));
            // Gamma校正
            mapped = pow(mapped, vec3(1.0 / gamma));
            color = vec4(mapped, 1.0);
          }</pre>
        <p>有了Reinhard色调映射的应用，我们不再会在场景明亮的地方损失细节。当然，这个算法是倾向明亮的区域的，暗的区域会不那么精细也不那么有区分度。</p>
      </section>
      <section class="clear"></section>
      <section>
        <h4>曝光色调映射算法</h4>
        <p>另一个色调映射应用是曝光(Exposure)参数的使用。<a href="#hdr">HDR</a>图片包含在不同曝光等级的细节。如果我
          们有一个场景要展现日夜交替，我们当然会在白天使用低曝光，在夜间使用高曝光，就像人眼调节方式一样。有了这个
          曝光参数，我们可以去设置可以同时在白天和夜晚不同光照条件工作的光照参数，我们只需要调整曝光参数就行了。
          这个方法纯粹就是凑一个函数，没人知道应该如何改进。属于粗暴地合成。</p>
        <pre>
          uniform float exposure;
          void main(){
              const float gamma = 2.2;
              vec3 hdrColor = texture(hdrBuffer, TexCoords).rgb;
              // 曝光色调映射
              vec3 mapped = vec3(1.0) - exp(-hdrColor * exposure);
              // Gamma校正
              mapped = pow(mapped, vec3(1.0 / gamma));
              color = vec4(mapped, 1.0);
          }</pre>
        <p><strong>曲线</strong></p>
        <p><img src="img/CEToneMapping.png"></p>
      </section>
      <section>
        <h4>FilmicToneMapping</h4>
        <p>这个方法的本质是把原图和让艺术家用专业照相软件模拟胶片的感觉，人肉tone mapping后的结果去做曲线拟合，得到
          一个高次曲线的表达式。这样的表达式应用到渲染结果后，就能在很大程度上自动接近人工调整的结果。</p>
        <pre>
        float3 F(float3 x)
        {
          const float A = 0.22f;
          const float B = 0.30f;
          const float C = 0.10f;
          const float D = 0.20f;
          const float E = 0.01f;
          const float F = 0.30f;

          return ((x * (A * x + C * B) + D * E) / (x * (A * x + B) + D * F)) - E / F;
        }

        float3 Uncharted2ToneMapping(float3 color, float adapted_lum)
        {
          const float WHITE = 11.2f;
          return F(1.6f * adapted_lum * color) / F(WHITE);
        }
        </pre>
        <p>那些ABCDEF都是多项式的系数，而WHITE是个magic number，表示白色的位置。这个方法开启了tone mapping的新路径 ，
          让人们知道了曲线拟合的好处。并且，其他颜色空间的变换，比如gamma矫正，也可以一起合并到这个曲线里来，一次搞
          定，不会增加额外开销。缺点就是运算量有点大，两个多项式的计算，并且相除。</p>
        <p><strong>曲线</strong></p>
        <p><img src="img/FilmicToneMapping.png"></p>
      </section>
      <section>
        <h4>ACESToneMapping</h4>
        <p>Academy Color Encoding System（ACES），是一套颜色编码系统，或者说是一个新的颜色空间。它是一个通用的数据
          交换格式，一方面可以不同的输入设备转成ACES，另一方面可以把ACES在不同的显示设备上正确显示。不管你是LDR，
          还是HDR，都可以在ACES里表达出来。这就直接解决了VDR的问题，不同设备间都可以互通数据。</p>
        <p>然而对于实时渲染来说，没必要用全套ACES。因为第一，没有什么“输入设备”。渲染出来的HDR图像就是个线性的数
          据，所以直接就在ACES空间中。而输出的时候需要一次tone mapping，转到LDR或另一个HDR。也就是说，我们只要
          ACES里的非常小的一条路径，而不是纷繁复杂的整套体系。</p>
        <pre>
        float3 ACESToneMapping(float3 color, float adapted_lum)
        {
          const float A = 2.51f;
          const float B = 0.03f;
          const float C = 2.43f;
          const float D = 0.59f;
          const float E = 0.14f;

          color *= adapted_lum;
          return (color * (A * color + B)) / (color * (C * color + D) + E);
        }
        </pre>
        <p><strong>曲线</strong></p>
        <p><img src="img/ACESToneMapping.png"></p>
      </section>
      <section id="ldr">
        <h4>LDR</h4>
        <p>LDR（低动态范围）所有的颜色值都被限制在了[0,1]范围。</p>
        <div class="content"></div>
      </section>
      <section id="hdr">
        <h4>HDR</h4>
        <p>HDR (High Dynamic Range，高动态范围)，在摄影领域，指的是可以提供更多的动态范围和图像细节的一种技术手段。
          简单讲就是将不同曝光拍摄出的最佳细节的<a href="#ldr">LDR</a>图像合成后，就叫HDR，它能同时反映出场景最暗和最亮
          部分的细节。为什么需要多张图片？因为目前的单反相机的宽容度还是有限的，一张照片不能反映出高动态场景的所
          有细节。一张图片拍摄就必须要在暗光和高光之间做出取舍，只能亮部暗部两者取其一。但是通过HDR合成多张图片，
          却能达到我们想要的效果。</p>
        <p>在WebGL中，HDR具体指的是让我们能用超过1.0的数据表示颜色值。到目前为止，我们用的都是<a href="#ldr">LDR</a>。
          在现实当中，太阳，灯光这类光源它们的颜色值肯定是远远超出1.0的范围的。</p>
        <div class="content"></div>
      </section>
    </section>
    <section id="bloom" class="section1">
      <div class="title">Bloom（泛光）</div>
      <p>Bloom 泛光 (或者眩光)，是用来模拟光源那种发光或发热的技术。区分明亮光源的方式是使它们发出光芒，光源的光芒向四周发散，
        这样观察者就会产生光源或亮区的确是强光区。Bloom使我们感觉到一个明亮的物体真的有种明亮的感觉。而Bloom和
        <a href="#hdr">HDR</a>的结合使用能非常完美地展示光源效果。</p>
      <section>
        <h4>Bloom处理过程</h4>
        <div class="content">
          <ul class="ul-1-num">
            <li>
              <strong>提取亮色</strong>
              <p>首先我们要从渲染出来的场景中提取两张图片。可以渲染场景两次，每次使用一个不同的不同的着色器渲染到不同的帧缓冲中，但可以使用一个叫做MRT（Multiple Render
                Targets多渲染目标）的小技巧，有了它我们能够在一个单独渲染处理中提取两个图片。在片元着色器的输出前，我们指定一个布局location标识符，这样我们便可控制一个片元着色器写入到哪个颜色缓冲：</p>
              <p>layout (location = 0) out vec4 FragColor;</p>
              <p>layout (location = 1) out vec4 BrightColor;</p>
              <p>使用多个片元着色器输出的必要条件是，有多个颜色缓冲附加到了当前绑定的帧缓冲对象上。直到现在，我们一直使用着 gl.COLOR_ATTACHMENT0，但通过使用
                gl.COLOR_ATTACHMENT1，可以得到一个附加了两个颜色缓冲的帧缓冲对象。
              <p><strong>帧缓冲封装：</strong></p>
              <pre>
          /**
            * 创建帧缓冲
            * * gl: 上下文
            * * opt: 参数对象
            * * * texs：颜色缓冲数量
            * * width:
            * * height:
            */
          function createFramebuffer(gl,opt,width,height){
            const fb = gl.createFramebuffer();      // 创建帧缓冲
            gl.bindFramebuffer(gl.FRAMEBUFFER, fb); // 绑定帧缓冲
            const framebufferInfo = {
                framebuffer: fb,
                textures: []
            };
            const texs = opt.texs || 1;       // 颜色缓冲数量
            const depth = !!opt.depth;

            // 创建纹理
            for(let i = 0;i < texs;i++){
                const tex = initTexture(gl, opt, width, height);
                framebufferInfo.textures.push(tex);
                gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0 + i, gl.TEXTURE_2D, tex, 0);
            }

            // SECTION 创建用于保存深度的渲染缓冲区
            if(depth) {
                const depthBuffer = gl.createRenderbuffer();
                gl.bindRenderbuffer(gl.RENDERBUFFER, depthBuffer);
                gl.renderbufferStorage(gl.RENDERBUFFER, gl.DEPTH_COMPONENT16, width, height);
                gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.DEPTH_ATTACHMENT, gl.RENDERBUFFER, depthBuffer);
            }
            // 检查帧缓冲区对象
            const e = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
            if (gl.FRAMEBUFFER_COMPLETE !== e) {
                throw new Error('Frame buffer object is incomplete: ' + e.toString());
            }

            // 解绑帧缓冲区对象
            gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            gl.bindTexture(gl.TEXTURE_2D, null);
            if(depth) gl.bindRenderbuffer(gl.RENDERBUFFER, null);

            return framebufferInfo;
        }
            </pre>
              <p>调用上面的函数创建包含两个颜色附件和一个深度附件的帧缓冲区.</p>
              <pre>
        // 场景帧缓存(2颜色附件 包含正常颜色 和 hdr高光颜色，1深度附件)
        const fbo = createFramebuffer(gl,{informat:gl.RGBA16F, type:gl.FLOAT, texs:2, depth:true});
              </pre>
              <p>在渲染的时候还需要显式告知WebGL我们正在通过gl.drawBuffers渲染到多个颜色缓冲，否则WebGL只会渲染到帧缓冲
                的第一个颜色附件，而忽略所有其他的。</p>
              <pre>
        // 采样到2个颜色附件
        gl.drawBuffers([gl.COLOR_ATTACHMENT0, gl.COLOR_ATTACHMENT1]);
              </pre>
              <p>当渲染到这个帧缓冲的时候，一个着色器使用一个布局location修饰符，然后把不同颜色值渲染到相应的颜色缓冲。
                这样就省去了为提取高光区域的额外渲染步骤。</p>
              <pre>
        #version 300 es
        precision highp float;
        layout (location = 0) out vec4 FragColor;
        layout (location = 1) out vec4 BrightColor;
        //...

        void main() {
            vec3 normal = normalize(vNormal);
            vec3 viewDirection = normalize(u_viewPosition - vposition);
            //...
            vec3 result = ambient + lighting;

            // 检查结果值是否高于某个门槛，如果高于就渲染到高光颜色缓存中
            float brightness = dot(result, vec3(0.2126, 0.7152, 0.0722));
            if(brightness > 1.0){
                BrightColor = vec4(result, 1.0);
            } else {
                BrightColor = vec4(0.0, 0.0, 0.0, 1.0);
            }
            FragColor = vec4(result, 1.0);
        }
              </pre>
              <p>
                这里先正常计算光照，将其传递给第一个片元着色器的输出变量FragColor。然后我们使用当前储存在FragColor的东西来决定它的亮度是否超过了一定阈限。我们通过恰当地将其转为灰度的方式计算一个fragment的亮度，如果它超过了一定阈限，我们就把颜色输出到第二个颜色缓冲，那里保存着所有亮部。</p>
              <p>这也说明了为什么泛光在<a href="#hdr">HDR</a>基础上能够运行得很好。因为<a href="#hdr">HDR</a>中，我们可以将颜色值指定超过1.0这个默认的范围，我们能够得到对一个图像中的亮度的更好的控制权。没有<a
                  href="#hdr">HDR</a>我们必须将阈限设置为小于1.0的数，虽然可行，但是亮部很容易变得很多，这就导致光晕效果过重。</p>
              <p>有了一个提取出的亮区图像，我们现在就要把这个图像进行模糊处理。</p>
            </li>
            <li>
              <strong>高斯模糊</strong>
              <p>
                要实现高斯模糊过滤需要一个二维四方形作为权重，从这个二维高斯曲线方程中去获取它。然而这个过程有个问题，
                就是很快会消耗极大的性能。以一个32×32的模糊kernel为例，我们必须对每个fragment从一个纹理中采样1024次！</p>
              <p>
                幸运的是，高斯方程有个非常巧妙的特性，它允许我们把二维方程分解为两个更小的方程：一个描述水平权重，另一个
                描述垂直权重。我们首先用水平权重在整个纹理上进行水平模糊，然后在经改变的纹理上进行垂直模糊。利用这个特性，结果是一样的，但是可以节省难以置信的性能，因为我们现在只需做32+32次采样，不再是1024了！这叫做两步高斯模糊。</p>
              <p>这意味着我们如果对一个图像进行模糊处理，至少需要两步，最好使用帧缓冲对象做这件事。具体来说，我们将实现
                像乒乓球一样的帧缓冲来实现高斯模糊。意思是使用一对帧缓冲，我们把另一个帧缓冲的颜色缓冲放进当前的帧缓冲的颜色缓冲中，使用不同的着色效果渲染指定的次数。基本上就是不断地切换帧缓冲和纹理去绘制。这样我们先在场景纹理的第一个缓冲中进行模糊，然后在把第一个帧缓冲的颜色缓冲放进第二个帧缓冲进行模糊，接着将第二个帧缓冲的颜色缓冲放进第一个，循环往复。</p>
              <p><strong>高斯模糊的片元着色器:</strong></p>
              <pre>
          #version 300 es
          precision highp float;
          uniform sampler2D image;
          uniform bool horizontal;
          in vec2 texcoord;
          out vec4 FragColor;
          const float weight[5] = float[](0.2270270270, 0.1945945946, 0.1216216216, 0.0540540541, 0.0162162162);

          void main() {
              vec2 tex_offset = vec2(1.0 / float(textureSize(image, 0))); // 每个像素的尺寸
              vec3 result = texture(image, texcoord).rgb * weight[0];
              if (horizontal) {
                  for (int i = 0; i < 5; ++i) {
                      result += texture(image, texcoord + vec2(tex_offset.x * float(i), 0.0)).rgb * weight[i];
                      result += texture(image, texcoord - vec2(tex_offset.x * float(i), 0.0)).rgb * weight[i];
                  }
              } else {
                  for (int i = 0; i < 5; ++i) {
                      result += texture(image, texcoord + vec2(0.0, tex_offset.y * float(i))).rgb * weight[i];
                      result += texture(image, texcoord - vec2(0.0, tex_offset.y * float(i))).rgb * weight[i];
                  }
              }
              FragColor = vec4 (result, 1.0);
          }
              </pre>
              <p>
                这里使用一个比较小的高斯权重做例子，每次我们用它来指定当前fragment的水平或垂直样本的特定权重。你会发现我
                们基本上是将模糊过滤器根据我们在uniform变量horizontal设置的值分割为一个水平和一个垂直部分。通过用1.0除以
                纹理的大小（从textureSize得到一个vec2）得到一个纹理像素的实际大小，以此作为偏移距离的根据。</p>
              <p>
                接着为图像的模糊处理创建两个基本的帧缓冲，每个只有一个颜色缓冲纹理，调用上面封装好的createFramebuffer函
                数即可。
              </p>
              <pre>
          // 2乒乓帧缓存(都只包含1颜色附件)
          const hFbo = createFramebuffer(gl,{informat:gl.RGBA16F, type:gl.FLOAT});
          const vFbo = createFramebuffer(gl,{informat:gl.RGBA16F, type:gl.FLOAT});
              </pre>
              <p>得到一个HDR纹理后，我们用提取出来的亮区纹理填充一个帧缓冲，然后对其模糊处理6次（3次垂直3次水平）：</p>
            </li>
            <pre>
          /**
           * 乒乓帧缓存
           */
          gl.useProgram(pProgram.program);
          for(let i=0; i < 6; i++){
              bindFramebufferInfo(gl, i%2 ? hFbo:vFbo);
              setBuffersAndAttributes(gl, pProgram, pVao);
              setUniforms(pProgram,{
                  horizontal: i%2? true:false,
                  image: i == 0 ? fbo.textures[1]: i%2 ? vFbo.textures[0]: hFbo.textures[0], //第1次两个乒乓帧缓存都为空，因此第一次要将灯光纹理传入
              });
              drawBufferInfo(gl, pVao);
          }
            </pre>
            <p>每次循环根据渲染的是水平还是垂直来绑定两个缓冲其中之一，而将另一个绑定为纹理进行模糊。第一次迭代，因为两
              个颜色缓冲都是空的所以我们随意绑定一个去进行模糊处理。重复这个步骤6次，亮区图像就进行一个重复3次的高斯模糊
              了。这样我们可以对任意图像进行任意次模糊处理；高斯模糊循环次数越多，模糊的强度越大。</p>
            <li>
              <strong>纹理混合</strong>
              <p>有了场景的HDR纹理和模糊处理的亮区纹理，只需把它们结合起来就能实现泛光或称光晕效果了。最终的片元着色器要
                把两个纹理混合：</p>
              <pre>
          #version 300 es
          precision highp float;
          in vec2 texcoord;
          uniform sampler2D image;
          uniform sampler2D imageBlur;
          uniform bool bloom;
          out vec4 FragColor;
          const float exposure = 1.0;
          const float gamma = 2.2;

          void main() {
              vec3 hdrColor = texture(image, texcoord).rgb;
              vec3 bloomColor = texture(imageBlur, texcoord).rgb;
              if (bloom)
                  hdrColor += bloomColor;     //添加融合

              //色调映射
              // vec3 result = hdrColor / (hdrColor + vec3(1.0));
              vec3 result = vec3 (1.0) - exp(-hdrColor * exposure);
              //进行gamma校正
              result = pow(result, vec3 (1.0 / gamma));
              FragColor = vec4(result, 1.0);
          }
              </pre>
              <p>注意要在应用色调映射之前添加泛光效果。这样添加的亮区的泛光，也会柔和转换为LDR，光照效果相对会更好。把两
                个纹理结合以后，场景亮区便有了合适的光晕特效：</p>
              <p>这里只用了一个相对简单的高斯模糊过滤器，它在每个方向上只有5个样本。通过沿着更大的半径或重复更多次数的模
                糊，进行采样我们就可以提升模糊的效果。因为模糊的质量与泛光效果的质量正相关，提升模糊效果就能够提升泛光效
                果。</p>
            </li>
          </ul>
        </div>
      </section>
    </section>
    <section id="buffer" class="section1">
      <h4 class="title">缓冲区</h4>
      <section id="bufferObject">
        <h4>缓冲区对象</h4>
        <p>缓冲区对象是WebGL系统中的一块内存区域，我们可以一次性地向缓存区对象中填充大量的顶点数据，然后将这些数据保存在其中，供顶点使用。</p>
        <p>默认情况下，WebGL在颜色缓冲区中进行绘图，在开启隐藏面消除功能时，还会用到深度缓冲区。总之，绘制的结果图像是存储在颜色缓冲区中的。</p>
        <div class="content">
          <strong>使用缓冲区对象向着色器中传入多个数据步骤：</strong>
          <ul class="ul-1-num">
            <li>创建缓冲区对象（<a href="WebGL_API/javaScript API/gl.html#createBuffer" target="_blank">gl.createBuffer()</a>）
            </li>
            <li>绑定缓冲区对象（<a href="WebGL_API/javaScript API/gl.html#bindBuffer" target="_blank">gl.bindBuffer()</a>）
            </li>
            <li>将数据写入缓冲区对象（<a href="WebGL_API/javaScript API/gl.html#bufferData" target="_blank">gl.bufferData()</a>）
            </li>
            <li>将缓冲区对象分配给一个attribute变量（<a href="WebGL_API/javaScript API/gl.html#vertexAttribPointer"
                                          target="_blank">gl.vertexAttribPointer()</a>）
            </li>
            <li>开启attribute变量（<a href="WebGL_API/javaScript API/gl.html#enableVertexAttribArray"
                                 target="_blank">gl.enableVertexAttribArray()</a>）
            </li>
          </ul>
          <strong>实例</strong>
          <ul class="ul-1-num">
            <li><a href="WebGL编程指南/ch3/MultiPoints.html" target="_blank">显示多个顶点</a></li>
          </ul>
        </div>
      </section>
      <section id="depthBuffer">
        <h4>深度缓存区</h4>
        <p>深度缓存区是一个中间对象，其作用就是帮助WebGL进行隐藏面消除。如果隐藏面消除，就必须知道每个几何图形的深度信息，而深度缓冲区就是用来存储深度信息的（Z缓冲区）。</p>
      </section>
      <section id="renderbufferObject">
        <h4>渲染缓冲区对象</h4>
        <p>渲染缓冲区对象表示一种更加通用的绘图区域，可以向其中写入多种类型的数据。</p>
      </section>
      <section id="framebuffer">
        <h4>帧缓冲区对象</h4>
        <p>帧缓冲区对象可以用来代替<strong>颜色缓冲区</strong>或<a href="#depthBuffer">深度缓冲区</a>。绘制操作不是直接发生在帧缓冲区中的，而是发生在帧缓冲区所关联的对象上。</p>
        <p>绘制在帧缓冲中的对象并不会直接显示在canvas上，可以先对帧缓冲区的内容进行一些处理，或者直接用其中的内容作为纹理图像。</p>
        <p>在帧缓冲区中进行绘制的过程又称为离屏绘制。</p>
        <div class="content">
          <h4>帧缓冲区所关联的对象：</h4>
          <ul class="ul-1-num">
            <li>颜色关联对象(代替颜色缓冲区)</li>
            <li>深度关联对象(代替深度缓冲区)</li>
            <li>模板关联对象(代替模板缓冲区)</li>
          </ul>
          <p><strong>关联对象类型：</strong>每一个关联对象可以是两种类型：纹理对象 或 <a href="#renderbufferObject">渲染缓冲区对象</a>。</p>
          <h4>帧缓冲区使用步骤:</h4>
          <ul class="ul-1-num">
            <li>创建帧缓冲区对象<a href="WebGL_API/javaScript%20API/gl.html#createFramebuffer" target="_blank">（gl.createFramebuffer()）</a>
            </li>
            <li>创建纹理对象并设置其尺寸和参数<a href="WebGL_API/javaScript%20API/gl.html#texture" target="_blank">（gl.createTexture()...）</a>
            </li>
            <li>创建渲染缓冲区<a href="WebGL_API/javaScript%20API/gl.html#renderBuffer"
                          target="_blank">（gl.createRenderBuffer）</a></li>
            <li>绑定渲染缓冲区并设置其尺寸<a href="WebGL_API/javaScript%20API/gl.html#renderBuffer" target="_blank">（gl.bindRenderBuffer）</a>
            </li>
            <li>将帧缓冲区的颜色关联对象指定为一个纹理对象<a href="WebGL_API/javaScript%20API/gl.html#framebufferTexture2D" target="_blank">（gl.framebufferTexture2D）</a>
            </li>
            <li>将帧缓冲区的深度关联对象指定为一个渲染缓冲区对象<a href="WebGL_API/javaScript%20API/gl.html#framebufferRenderbuffer"
                                           target="_blank">（gl.framebufferRenderbuffer）</a></li>
            <li>检查帧缓冲区是否正确配置<a href="WebGL_API/javaScript%20API/gl.html#checkFramebufferStatus" target="_blank">（gl.checkFramebufferStatus）</a>
            </li>
            <li>在帧缓冲区中进行绘制<a href="WebGL_API/javaScript%20API/gl.html#checkFramebufferStatus" target="_blank">（gl.checkFramebufferStatus）</a>
            </li>
          </ul>
          <h4>实例</h4>
          <ul class="ul-1-num">
            <li><a href="WebGL编程指南/ch10/FramebufferObject.html" target="_blank">帧缓冲对象实例</a></li>
          </ul>
        </div>
      </section>
      <section id="float_framebuffer">
        <h4>浮点帧缓冲</h4>
        <p>当帧缓冲使用标准化的定点格式(像gl.RGB)为其颜色缓冲的内部格式，WebGL会在将这些值存入帧缓冲前自动将其约束到0.0
          到1.0之间。这一操作对大部分帧缓冲格式都是成立的，除了专门用来存放被拓展范围值的浮点格式。</p>
        <p>WebGL扩大颜色值范围的方法就是：把颜色的格式设置成16位浮点数或者32位浮点数，即把帧缓冲的颜色缓冲的内部格式设
          定成 gl.RGB16F, gl.RGBA16F, gl.RGB32F 或者 gl.RGBA32F，这些帧缓冲被叫做浮点帧缓冲(Floating Point Framebuffer)，
          浮点帧缓冲可以存储超过0.0到1.0范围的浮点值，所以非常适合<a href="#hdr">HDR</a>渲染。</p>
        <div class="content">
          <strong>创建浮点帧缓冲:</strong>
          <p>gl.bindTexture(gl.TEXTURE_2D, colorBuffer);</p>
          <p>gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB16F, SCR_WIDTH, SCR_HEIGHT, 0, gl.RGB, gl.FLOAT, NULL);</p>
          <p>帧缓冲默认一个颜色分量只占用8位(bits)。当使用一个使用32位每颜色分量时(使用gl.RGB32F 或者 gl.RGBA32F)，我们
            需要四倍的内存来存储这些颜色。所以除非你需要一个非常高的精确度，32位不是必须的，使用 gl.RGB16F就足够了。</p>
        </div>
      </section>
    </section>
    <section id="WebGL_Event" class="section1">
      <h4 class="title">WebGL相关事件</h4>
      <section id="ContextLost">
        <h4>上下文丢失事件</h4>
        <div class="content">
          <strong>说明</strong>
          <table border="1">
            <tr>
              <th colspan="2">上下文丢失事件</th>
            </tr>
            <tr>
              <th>事件</th>
              <th>描述</th>
            </tr>
            <tr>
              <td>webglcontextlost</td>
              <td>当WebGl上下文丢失时触发</td>
            </tr>
            <tr>
              <td>webglcontextrestored</td>
              <td>当浏览器完成WebGL系统的重置后触发</td>
            </tr>
          </table>
          <strong>使用</strong>
          <p>只能使用addEventListener来注册事件</p>
          <strong>实例</strong>
          <ul class="ul-1-num">
            <li><a href="WebGL编程指南/ch10/RotatingTriangle_contextLost.html" target="_blank">上下文丢失</a></li>
          </ul>
        </div>
      </section>
    </section>
    <section id="JavaScript" class="section1">
      <div class="title">javaScript相关函数概念</div>
      <section>
        <h4>着色器对象（shader object）</h4>
        <p>着色器对象管理一个顶点着色器或一个片元着色器。每一个着色器都有一个着色器对象。</p>
      </section>
      <section>
        <h4>程序对象（program object）</h4>
        <p>管理着色器对象的容器。WebGL中，一个程序对象必须包含一个顶点着色器和一个片元着色器。</p>
        <p><img src="img/9_10.png"></p>
      </section>
      <section>
        <h4>帧缓冲对象（framebuffer object）</h4>
        <p>可以用来代替颜色缓冲区或深度缓冲区。绘制在帧缓冲区中的对象并不会直接显示在canvas上，你可以先对帧缓冲区中的内容进行一些处理再显示，或则直接用其中的内容作为纹理图像.
          在帧缓冲区中进行绘制的过程又称为离屏绘制（offscreen drawing）。绘制操作不是直接发生在帧缓冲区中的，而是发生在帧缓冲区所关联（attachment）的对象上。</p>
        <div class="content">
          <strong>一个帧缓冲区有三个关联对象：</strong>
          <ul class="ul-1">
            <li>颜色关联对象（color attachment）,对应颜色缓冲区</li>
            <li>深度关联对象（depth attachment）,对应深度缓冲区</li>
            <li>模板关联对象（stencil attachment）,对应模板缓冲区</li>
          </ul>
          <strong>每个关联对象的类型:</strong>
          <ul class="ul-1">
            <li>纹理对象</li>
            <li>渲染缓冲区对象（renderbuffer object）</li>
          </ul>
        </div>
      </section>
      <section>
        <h4>渲染缓冲区对象（renderbuffer object）</h4>
        <p>表示一种更佳通用的绘图区域，可以向其中写入多种数据。</p>
      </section>
    </section>
    <section id="inner" class="section1">
      <div class="title">WebGL内置功能</div>
      <section id="depth_test">
        <h4>隐藏面消除</h4>
        <p>可以消除那些被遮挡的表面，绘制时，就不需要顾及各个物体在缓存区中的顺序。</p>
        <div class="content">
          <strong>开启流程：</strong>
          <ul class="ul-1-num">
            <li>
              开启隐藏面消除功能<br>
              <a href="WebGL_API/javaScript%20API/gl.html#enable"
                 target="_blank">gl.enable(DEPTH_TEST)</a>
            </li>
            <li>
              在绘制之前，清除深度缓存区<br>
              <a href="WebGL_API/javaScript%20API/gl.html#clear" target="_blank">gl.clear(gl.DEPTH_BUFFER_BIT)</a>
            </li>
          </ul>
          <strong>实例</strong>
          <ul class="ul-1-num">
            <li><a href="WebGL编程指南/ch07/DepthBuffer.html" target="_blank">隐藏面消除</a></li>
          </ul>
          <strong>问题:</strong>
          <ul class="ul-1-num">
            <li><a href="#basicConcept">深度冲突</a></li>
          </ul>
        </div>
      </section>
      <section id="ploygonOffset">
        <h4>多边形偏移</h4>
        <p>在使用隐藏面消除时，解决深度缓存的问题</p>
        <div class="content">
          <strong>启动功能</strong>
          <ul class="ul-1-num">
            <li>
              启动多边形偏移<br>
              <a href="WebGL_API/javaScript%20API/gl.html#enable">gl.enable(gl.POLYGON_OFFSET_FILL)</a>
            </li>
            <li>
              在绘制之前，指定用来计算偏移量的参数<br>
              <a href="WebGL_API/javaScript%20API/gl.html#polygonOffset">gl.polygonOffset(1.0,1.0)</a>
            </li>
          </ul>
          <strong>实例</strong>
          <ul class="ul-1-num">
            <li><a href="WebGL编程指南/ch07/Zfighting.html" target="_blank">深度缓存</a></li>
          </ul>
        </div>
      </section>
      <section id="polygonCulling">
        <h4>多边形剔除</h4>
        <p>多边形剔除可以用来减少渲染的面</p>
      </section>
    </section>
    <section id="light" class="section1">
      <div class="title">光照</div>
      <div class="content">
        <strong>反射：</strong>
        <ul class="ul-1-num">
          <li>漫反射：漫反射光颜色 = 入射光颜色 * 表面基地颜色 * cos</li>
          <li>环境反射：漫反射光颜色 = 入射光颜色 * 表面基地颜色</li>
        </ul>
      </div>
    </section>
    <section id="WebGL-example" class="section1">
      <div class="title">WebGL相关实例</div>
      <section id="example_1">
        <h4>WebGL编程指南</h4>
        <div class="content">
          <ul>
            <li><a href="WebGL编程指南/index.html" target="_blank">WebGL编程指南实例</a></li>
            <li><a href="WebGL编程指南/lib/cuon-matrix说明.html" target="_blank">矩阵库说明（cuon-matrix.js）</a></li>
          </ul>
        </div>
      </section>
      <section id="example_2">
        <h4>水箱效果</h4>
        <div class="content">
          <ul>
            <li><a href="example/webgl-water/index.html" target="_blank">水箱效果</a></li>
          </ul>
        </div>
      </section>
    </section>
    <section id="book" class="section1">
      <div class="title">相关资料</div>
      <section>
        <h4>《Foundations of Game Engine Development》</h4>
        <div class="content">
          <a href="http://foundationsofgameenginedev.com/" target="_blank">连接地址</a>
        </div>
      </section>
      <section>
        <h4>shadertoy</h4>
        <p><a href="https://www.shadertoy.com" target="_blank">https://www.shadertoy.com</a></p>
      </section>
    </section>
    <section class="section1">
      <div class="title">加载格式</div>
      <section>
        <h4>gltf</h4>
        <div class="content">
          <a href="https://github.com/khronosgroup/gltf#gltf-tools" target="_blank">gltf格式转换格式地址</a>
        </div>
      </section>
    </section>
  </div>
</div>
</body>
</html>